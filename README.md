# Multimodal-Fake-Review-Detection



The proliferation of AI-generated content presents a growing challenge in discerning authentic user reviews from artificially generated ones. In this work, we introduce a multimodal framework that detects fake reviews by jointly analyzing review text and associated images. Using a combination of transformer-based text encoders and CLIP-style vision models, our system learns to fuse semantic and visual cues for robust classification. We curate a hybrid dataset of real and synthetically generated reviews, propose novel multimodal fusion techniques, and release an open-source toolkit for fake review detection. Our results indicate significant performance gains in the multimodal setting, establishing a strong baseline for this emerging problem.
